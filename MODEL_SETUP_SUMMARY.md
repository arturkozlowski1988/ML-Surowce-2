# ğŸ¤– Podsumowanie Konfiguracji Lokalnego Modelu LLM

**Data:** 28 grudnia 2024  
**Status:** âœ… Skonfigurowano i przetestowano

---

## ğŸ“Š Analiza Projektu

**AI Supply Assistant** to inteligentny asystent zakupowy dla firm produkcyjnych, ktÃ³ry:

- Analizuje zuÅ¼ycie surowcÃ³w
- Prognozuje zapotrzebowanie
- Wykrywa anomalie
- Generuje rekomendacje zakupowe

**GÅ‚Ã³wne zastosowania AI:**

- Analiza danych produkcyjnych
- Interpretacja trendÃ³w biznesowych
- Rekomendacje dla dziaÅ‚Ã³w zakupÃ³w
- Optymalizacja Å‚aÅ„cucha dostaw

---

## ğŸ¯ DostÄ™pne Modele

### Model DomyÅ›lny: Qwen2.5-7B-Instruct â­

| Parametr | WartoÅ›Ä‡ |
|----------|---------|
| **Rozmiar** | 3.55 GB |
| **PrÄ™dkoÅ›Ä‡** | ~3.5 sÅ‚Ã³w/s |
| **Kontekst** | 32k tokenÃ³w |
| **JakoÅ›Ä‡** | WyÅ¼sza |

### Model Szybki: Qwen2.5-3B-Instruct

| Parametr | WartoÅ›Ä‡ |
|----------|---------|
| **Rozmiar** | 1.96 GB |
| **PrÄ™dkoÅ›Ä‡** | ~6 sÅ‚Ã³w/s |
| **Kontekst** | 32k tokenÃ³w |
| **JakoÅ›Ä‡** | Dobra |

### PorÃ³wnanie modeli

| Model | Rozmiar | Kontekst | PrÄ™dkoÅ›Ä‡ | Ocena dla projektu |
|-------|---------|----------|----------|-------------------|
| **Qwen2.5-7B** | **3.55 GB** | **32k** | ~3.5 w/s | **â­â­â­â­â­ DOMYÅšLNY** |
| Qwen2.5-3B | 1.96 GB | 32k | ~6 w/s | â­â­â­â­ Backup |

---

## ğŸ“¥ Lokalizacja Modeli

```
E:\ML Surowce 2\models\
â”œâ”€â”€ qwen2.5-7b-instruct-q3_k_m.gguf  # 3.55 GB - domyÅ›lny
â””â”€â”€ qwen2.5-3b-instruct-q4_k_m.gguf  # 1.96 GB - backup
```

---

## âš™ï¸ Konfiguracja .env

### DomyÅ›lna konfiguracja (Model 7B)

```bash
LOCAL_LLM_PATH=models/qwen2.5-7b-instruct-q3_k_m.gguf
```

### Konfiguracja szybka (Model 3B)

```bash
LOCAL_LLM_PATH=models/qwen2.5-3b-instruct-q4_k_m.gguf
```

---

## ğŸš€ Jak uÅ¼ywaÄ‡

### W aplikacji Streamlit

1. Uruchom aplikacjÄ™:

   ```bash
   streamlit run main.py
   ```

2. PrzejdÅº do sekcji **"AI Assistant (GenAI)"**

3. Wybierz silnik AI: **"ğŸš€ Local LLM (Embedded)"**

4. Model bÄ™dzie przetwarzaÅ‚ dane **lokalnie** - peÅ‚na prywatnoÅ›Ä‡! ğŸ”’

### Zalety lokalnego modelu

- âœ… **100% prywatnoÅ›ci** - dane nie opuszczajÄ… komputera
- âœ… **Bez kosztÃ³w API** - dziaÅ‚a offline
- âœ… **Szybki** - brak opÃ³ÅºnieÅ„ sieciowych
- âœ… **RODO-compliant** - idealne dla danych wraÅ¼liwych

---

## ğŸ”§ Parametry techniczne

```python
# Model domyÅ›lny (7B)
Model: Qwen2.5-7B-Instruct-Q3_K_M
Rozmiar: 3.55 GB
Kontekst: 32,768 tokenÃ³w (32k)
Kwantyzacja: Q3_K_M
WÄ…tki CPU: 18 (auto-detect: CPU count - 2)
Framework: llama-cpp-python 0.3.2
```

---

## ğŸ§ª Testowanie Modeli

Uruchom skrypt porÃ³wnawczy:

```bash
python scripts/compare_models.py
```

---

## ğŸ“š Å¹rÃ³dÅ‚a

- **Model:** <https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF>
- **Dokumentacja Qwen2.5:** <https://github.com/QwenLM/Qwen2.5>
- **llama-cpp-python:** <https://github.com/abetlen/llama-cpp-python>

---

## âœ¨ Podsumowanie

Model **Qwen2.5-7B-Instruct** zostaÅ‚ wybrany jako domyÅ›lny dla tego projektu:

1. **WyÅ¼sza jakoÅ›Ä‡** odpowiedzi niÅ¼ model 3B
2. Specjalizuje siÄ™ w **analizie biznesowej**
3. Ma **32k kontekst** - wystarczajÄ…cy dla zÅ‚oÅ¼onych analiz
4. DziaÅ‚a **lokalnie** - peÅ‚na prywatnoÅ›Ä‡ danych
5. Model 3B zachowany jako **szybszy backup**

**Status instalacji: âœ… GOTOWE DO UÅ»YCIA**

---

*Aktualizacja konfiguracji: 28 grudnia 2024*
