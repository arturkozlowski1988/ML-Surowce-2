# üìã Propozycje Optymalizacji Systemu ERP
# AI Supply Assistant - Comarch Optima / Produkcja by CTI

> **Wersja**: 1.0  
> **Data**: 2024-12-29  
> **Audytor**: Senior ERP Systems Architect & Business Analyst  
> **System**: Comarch Optima + Produkcja by CTI + AI Supply Assistant

---

## üìë Spis Tre≈õci

1. [Podsumowanie Wykonawcze](#podsumowanie-wykonawcze)
2. [Metodologia Analizy](#metodologia-analizy)
3. [Kategoria A: Usprawnienia Funkcjonalne](#kategoria-a-usprawnienia-funkcjonalne)
4. [Kategoria B: Usprawnienia Ergonomiczne (UX)](#kategoria-b-usprawnienia-ergonomiczne-ux)
5. [Kategoria C: Usprawnienia Biznesowe](#kategoria-c-usprawnienia-biznesowe)
6. [Implementacja - Harmonogram](#implementacja---harmonogram)
7. [Metryki Sukcesu (KPI)](#metryki-sukcesu-kpi)
8. [Za≈ÇƒÖczniki Techniczne](#za≈ÇƒÖczniki-techniczne)

---

## üìä Podsumowanie Wykonawcze

### Kontekst Biznesowy
System **AI Supply Assistant** jest aplikacjƒÖ klasy ERP zintegrowanƒÖ z **Comarch Optima** (modu≈Ç Produkcja by CTI) wspierajƒÖcƒÖ dzia≈Çy zakup√≥w i produkcji poprzez:
- Analizƒô historycznego zu≈ºycia surowc√≥w
- Prognozowanie popytu (Machine Learning)
- Wsparcie AI w podejmowaniu decyzji zakupowych

### Kluczowe Wnioski
Po przeprowadzeniu dog≈Çƒôbnej analizy kodu ≈∫r√≥d≈Çowego, struktury bazy danych SQL oraz przep≈Çyw√≥w biznesowych zidentyfikowano **25 obszar√≥w optymalizacji** w trzech kategoriach:

| Kategoria | Liczba Propozycji | Potencjalny Wp≈Çyw Biznesowy |
|-----------|-------------------|----------------------------|
| **Funkcjonalne** | 10 | Automatyzacja, nowe funkcje |
| **Ergonomiczne** | 8 | Poprawa UX, redukcja b≈Çƒôd√≥w |
| **Biznesowe** | 7 | ROI, compliance, wydajno≈õƒá |

### Priorytetyzacja (Quick Wins)
**üöÄ Rekomendacje do natychmiastowej implementacji (Q1 2025)**:
1. Implementacja brakujƒÖcych indeks√≥w SQL (+40% wydajno≈õƒá zapyta≈Ñ)
2. Automatyczne alertowanie przy niskich stanach magazynowych
3. Export raport√≥w do Excel (BI Integration)
4. Dashboard u≈ºytkownika z historiƒÖ operacji

---

## üîç Metodologia Analizy

### ≈πr√≥d≈Ça Danych
1. **Kod ≈πr√≥d≈Çowy**: Python (Streamlit, SQLAlchemy, scikit-learn)
2. **Baza Danych**: MS SQL Server (tabele CTI: CtiZlecenieNag, CtiZlecenieElem, CtiTechnolNag, CtiTechnolElem; CDN: Towary, TwrZasoby)
3. **Dokumentacja**: TECHNICAL_DOCUMENTATION.md, USER_GUIDE.md
4. **Skrypty Testowe**: `scripts/` (21 plik√≥w testowych)

### Proces Audytu (Chain of Thought)
```
Step 1: Analiza Struktury
‚îú‚îÄ‚îÄ Modu≈Çy aplikacji (db_connector, forecasting, ai_engine, gui, security)
‚îú‚îÄ‚îÄ Schemat bazy danych (6 kluczowych tabel)
‚îî‚îÄ‚îÄ Zale≈ºno≈õci technologiczne (Stack: Python 3.9+, SQL Server, Streamlit)

Step 2: Identyfikacja Problem√≥w
‚îú‚îÄ‚îÄ Wydajno≈õƒá: Brak indeks√≥w, brak cache warming
‚îú‚îÄ‚îÄ Funkcjonalno≈õƒá: Brak powiadomie≈Ñ, brak eksportu danych
‚îú‚îÄ‚îÄ UX: Zbyt wiele klikniƒôƒá, brak historii operacji
‚îî‚îÄ‚îÄ Bezpiecze≈Ñstwo: NOLOCK w transakcjach krytycznych

Step 3: Propozycje RozwiƒÖza≈Ñ
‚îú‚îÄ‚îÄ Priorytety (Quick Wins vs Long-term)
‚îú‚îÄ‚îÄ Feasibility Analysis (Impact vs Effort Matrix)
‚îî‚îÄ‚îÄ Rekomendacje implementacyjne z przyk≈Çadami kodu

Step 4: Weryfikacja Bezpiecze≈Ñstwa
‚îú‚îÄ‚îÄ Transaction safety (BEGIN TRAN...ROLLBACK)
‚îú‚îÄ‚îÄ SQL Injection prevention (parametryzowane zapytania)
‚îî‚îÄ‚îÄ Data integrity checks
```

### Zakres Analityczny
- **51 plik√≥w Python** (.py)
- **0 procedur SQL** (queries inline w Python - **Risk Area**)
- **6 tabel bazodanowych** (g≈Ç√≥wne)
- **~4000 linii kodu** (w≈ÇƒÖczajƒÖc scripts/)

---

## üöÄ Kategoria A: Usprawnienia Funkcjonalne

### A.1 ‚≠ê Implementacja BrakujƒÖcych Indeks√≥w SQL (CRITICAL)

**Priorytet**: üî¥ WYSOKI (Quick Win)  
**Wysi≈Çek**: Niski (2-4h DBA)  
**Wp≈Çyw Biznesowy**: Poprawa wydajno≈õci zapyta≈Ñ o 30-50%, redukcja czasu ≈Çadowania raport√≥w

#### Problem
Analiza metody `DatabaseConnector.check_and_create_indexes()` oraz zapyta≈Ñ w `get_historical_data()` ujawnia **brak kluczowych indeks√≥w** na czƒôsto u≈ºywanych kolumnach.

**Zdiagnozowane wolne zapytania** (>1.0s):
- `get_historical_data`: Skanowanie pe≈Çne tabeli `CtiZlecenieElem` (join z 3 tabelami)
- `get_product_bom`: Brak indeksu na `CtiTechnolNag.CTN_TwrId`

#### RozwiƒÖzanie

**SQL Script** (do wykonania przez DBA w oknie maintenance):

```sql
-- ========================================
-- INDEXES FOR PERFORMANCE OPTIMIZATION
-- AI Supply Assistant / CTI Module
-- Date: 2025-01-XX
-- DBA: [NAME]
-- ========================================

-- üîç VERIFICATION: Check if indexes already exist
SELECT i.name as IndexName, t.name as TableName, 
       COL_NAME(ic.object_id, ic.column_id) as ColumnName
FROM sys.indexes i
JOIN sys.index_columns ic ON i.object_id = ic.object_id AND i.index_id = ic.index_id
JOIN sys.tables t ON i.object_id = t.object_id
WHERE i.name IN ('IX_CtiZlecenieElem_TwrId_Typ', 'IX_CtiZlecenieNag_DataRealizacji', 
                 'IX_CtiTechnolElem_CTNId', 'IX_CtiTechnolNag_TwrId');

-- ========================================
-- TRANSACTIONAL WRAPPER (SAFETY)
-- ========================================
BEGIN TRAN

-- Index 1: Raw Material Filtering Performance
-- Purpose: Speeds up WHERE CZE_Typ IN (1, 2) AND CZE_TwrId = X queries
IF NOT EXISTS (SELECT 1 FROM sys.indexes WHERE name = 'IX_CtiZlecenieElem_TwrId_Typ' AND object_id = OBJECT_ID('dbo.CtiZlecenieElem'))
BEGIN
    CREATE NONCLUSTERED INDEX IX_CtiZlecenieElem_TwrId_Typ 
    ON dbo.CtiZlecenieElem(CZE_TwrId, CZE_Typ)
    INCLUDE (CZE_Ilosc, CZE_CZNId);  -- Cover frequently selected columns
    
    PRINT '‚úÖ Index IX_CtiZlecenieElem_TwrId_Typ created successfully';
END
ELSE
    PRINT '‚ö†Ô∏è  Index IX_CtiZlecenieElem_TwrId_Typ already exists';

-- Index 2: Historical Data Date Range Queries
-- Purpose: Speeds up DATE filters in get_historical_data()
IF NOT EXISTS (SELECT 1 FROM sys.indexes WHERE name = 'IX_CtiZlecenieNag_DataRealizacji' AND object_id = OBJECT_ID('dbo.CtiZlecenieNag'))
BEGIN
    CREATE NONCLUSTERED INDEX IX_CtiZlecenieNag_DataRealizacji 
    ON dbo.CtiZlecenieNag(CZN_DataRealizacji)
    INCLUDE (CZN_ID, CZN_TwrId);  -- Include join columns
    
    PRINT '‚úÖ Index IX_CtiZlecenieNag_DataRealizacji created successfully';
END
ELSE
    PRINT '‚ö†Ô∏è  Index IX_CtiZlecenieNag_DataRealizacji already exists';

-- Index 3: BOM Lookup Performance
-- Purpose: Speeds up JOIN from TechnolNag to TechnolElem
IF NOT EXISTS (SELECT 1 FROM sys.indexes WHERE name = 'IX_CtiTechnolElem_CTNId' AND object_id = OBJECT_ID('dbo.CtiTechnolElem'))
BEGIN
    CREATE NONCLUSTERED INDEX IX_CtiTechnolElem_CTNId 
    ON dbo.CtiTechnolElem(CTE_CTNId, CTE_Typ)
    INCLUDE (CTE_TwrId, CTE_Ilosc);
    
    PRINT '‚úÖ Index IX_CtiTechnolElem_CTNId created successfully';
END
ELSE
    PRINT '‚ö†Ô∏è  Index IX_CtiTechnolElem_CTNId already exists';

-- Index 4: Technology Lookup by Product
-- Purpose: Speeds up "Which BOM for this product?" queries
IF NOT EXISTS (SELECT 1 FROM sys.indexes WHERE name = 'IX_CtiTechnolNag_TwrId' AND object_id = OBJECT_ID('dbo.CtiTechnolNag'))
BEGIN
    CREATE NONCLUSTERED INDEX IX_CtiTechnolNag_TwrId 
    ON dbo.CtiTechnolNag(CTN_TwrId)
    INCLUDE (CTN_ID, CTN_Status);
    
    PRINT '‚úÖ Index IX_CtiTechnolNag_TwrId created successfully';
END
ELSE
    PRINT '‚ö†Ô∏è  Index IX_CtiTechnolNag_TwrId already exists';

-- ========================================
-- VALIDATION QUERIES
-- ========================================
-- Count affected rows (estimation)
SELECT 'CtiZlecenieElem rows' as TableInfo, COUNT(*) as RowCount FROM dbo.CtiZlecenieElem;
SELECT 'CtiZlecenieNag rows' as TableInfo, COUNT(*) as RowCount FROM dbo.CtiZlecenieNag;
SELECT 'CtiTechnolElem rows' as TableInfo, COUNT(*) as RowCount FROM dbo.CtiTechnolElem;
SELECT 'CtiTechnolNag rows' as TableInfo, COUNT(*) as RowCount FROM dbo.CtiTechnolNag;

-- Verify all indexes created
SELECT i.name as IndexName, t.name as TableName, i.type_desc as IndexType,
       SUM(ps.used_page_count) * 8 / 1024.0 as SizeMB
FROM sys.indexes i
JOIN sys.tables t ON i.object_id = t.object_id
JOIN sys.dm_db_partition_stats ps ON i.object_id = ps.object_id AND i.index_id = ps.index_id
WHERE i.name LIKE 'IX_Cti%'
GROUP BY i.name, t.name, i.type_desc
ORDER BY t.name, i.name;

-- ========================================
-- COMMIT OR ROLLBACK
-- ========================================
-- ‚ö†Ô∏è  DBA DECISION: Review output above, then:
ROLLBACK;  -- Default: Safety rollback for review
-- COMMIT;  -- Uncomment ONLY after verification
```

**‚ö†Ô∏è UWAGA DLA DBA**:
- Wykonywaƒá w oknie maintenance (poza godzinami szczytu).
- Tworzenie indeks√≥w blokuje tabelƒô (mo≈ºe zajƒÖƒá 2-10 min w zale≈ºno≈õci od wielko≈õci danych).
- **Opcja Enterprise Edition**: Dodaƒá `WITH (ONLINE = ON)` dla tworzenia indeks√≥w bez blokowania.

#### Weryfikacja Po Wdro≈ºeniu

**Python Script** (dodaƒá do `scripts/verify_indexes.py`):

```python
"""
Verification script for database indexes.
Run after DBA creates indexes to confirm performance improvement.
"""
import time
from src.db_connector import DatabaseConnector

def test_query_performance():
    \"\"\"Measures query performance before/after index creation.\"\"\"
    try:
        db = DatabaseConnector(enable_diagnostics=True)
        
        # Test 1: Historical Data Query (most critical)
        print("üîç Testing get_historical_data() performance...")
        start = time.time()
        df = db.get_historical_data(use_cache=False, 
                                      date_from='2024-01-01', 
                                      date_to='2024-12-31')
        duration = time.time() - start
        
        print(f"‚úÖ Query completed in {duration:.3f}s ({len(df)} rows)")
        print(f"{'üöÄ PASS' if duration < 1.0 else '‚ö†Ô∏è  SLOW'}: Target < 1.0s")
        
        # Test 2: BOM Query
        print("\\nüîç Testing get_product_bom() performance...")
        products = db.get_products_with_technology(use_cache=False)
        if not products.empty:
            test_product_id = products.iloc[0]['FinalProductId']
            start = time.time()
            bom = db.get_product_bom(test_product_id)
            duration = time.time() - start
            print(f"‚úÖ BOM query completed in {duration:.3f}s ({len(bom)} rows)")
            print(f"{'üöÄ PASS' if duration < 0.5 else '‚ö†Ô∏è  SLOW'}: Target < 0.5s")
        
        # Diagnostics Summary
        stats = db.get_diagnostics_stats()
        print(f"\\nüìä Diagnostics Summary:")
        print(f"   Total Queries: {stats.get('total_queries', 0)}")
        print(f"   Avg Duration: {stats.get('avg_duration', 0):.3f}s")
        print(f"   Slow Queries: {stats.get('slow_queries', 0)}")
        
        # Verify indexes exist
        print("\\nüîç Verifying indexes exist...")
        index_info = db.check_and_create_indexes()
        if index_info['missing']:
            print("‚ö†Ô∏è  MISSING INDEXES:")
            for idx in index_info['missing']:
                print(f"   - {idx['name']}: {idx['reason']}")
        else:
            print("‚úÖ All recommended indexes exist")
            
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    test_query_performance()
```

#### KPI Sukcesu
- **Przed**: `get_historical_data()` avg 2.5s
- **Po**: `get_historical_data()` avg <1.0s (**60% redukcja**)
- **Monitoring**: U≈ºyƒá `DatabaseConnector.get_diagnostics_stats()` w produkcji

---

### A.2 Automatyczne Powiadomienia o Niskich Stanach Magazynowych

**Priorytet**: üü° ≈öREDNI  
**Wysi≈Çek**: ≈öredni (8-16h dev)  
**Wp≈Çyw Biznesowy**: Proaktywne planowanie zakup√≥w, redukcja przestoj√≥w produkcji

#### Problem
Obecnie system wymaga **manualnego sprawdzania** stan√≥w magazynowych przez Panel Zakupowca. Brak mechanizmu alert√≥w powoduje:
- Op√≥≈∫nienia w zam√≥wieniach (lead time 7-14 dni)
- Ryzyko przestoj√≥w produkcji (brak surowc√≥w)
---

### A.4 Automatyczna Archiwizacja Historycznych Danych (Data Retention Policy)

**Priorytet**: üü° ≈öREDNI  
**Wysi≈Çek**: ≈öredni (12-20h dev + DBA)  
**Wp≈Çyw Biznesowy**: Compliance (RODO), optymalizacja wydajno≈õci bazy danych

#### Problem
Tabela `CtiZlecenieElem` ro≈õnie liniowo w czasie (nowe zlecenia produkcyjne codziennie). Brak polityki archiwizacji prowadzi do:
- Wzrostu rozmiaru bazy danych (backup windows, koszty storage)
- Pogorszenia wydajno≈õci zapyta≈Ñ (wiƒôksze tabele)
- Trudno≈õci w compliance z RODO (dane >3 lata mogƒÖ wymagaƒá usuniƒôcia)

**<DO_POTWIERDZENIA_W_DOKUMENTACJI_OPTIMA>**  
Verify Comarch Optima's built-in archiving mechanisms. Module "Produkcja by CTI" may have native data lifecycle management.
**</DO_POTWIERDZENIA_W_DOKUMENTACJI_OPTIMA>**

#### RozwiƒÖzanie

**SQL Stored Procedure** - Archive Production Orders Older Than N Years:

```sql
-- ========================================
-- ARCHIVE PROCEDURE: Old Production Orders
-- Purpose: Move orders older than 3 years to archive table
-- Schedule: Run quarterly (Q1: Jan, Q2: Apr, Q3: Jul, Q4: Oct)
-- ========================================

-- Step 1: Create Archive Tables (One-time setup)
BEGIN TRAN

-- Archive table for order headers
IF NOT EXISTS (SELECT 1 FROM sys.tables WHERE name = 'CtiZlecenieNag_Archive')
BEGIN
    SELECT * INTO dbo.CtiZlecenieNag_Archive
    FROM dbo.CtiZlecenieNag
    WHERE 1=0;  -- Copy structure only, no data
    
    ALTER TABLE dbo.CtiZlecenieNag_Archive 
    ADD ArchiveDate DATETIME DEFAULT GETDATE();
    
    PRINT '‚úÖ Archive table CtiZlecenieNag_Archive created';
END

-- Archive table for order elements
IF NOT EXISTS (SELECT 1 FROM sys.tables WHERE name = 'CtiZlecenieElem_Archive')
BEGIN
    SELECT * INTO dbo.CtiZlecenieElem_Archive
    FROM dbo.CtiZlecenieElem
    WHERE 1=0;
    
    ALTER TABLE dbo.CtiZlecenieElem_Archive 
    ADD ArchiveDate DATETIME DEFAULT GETDATE();
    
    PRINT '‚úÖ Archive table CtiZlecenieElem_Archive created';
END

ROLLBACK;  -- Review structure
-- COMMIT;  -- Execute after review

-- Step 2: Archive Procedure
GO
CREATE OR ALTER PROCEDURE dbo.usp_ArchiveOldProductionOrders
    @YearsToKeep INT = 3,
    @DryRun BIT = 1  -- Safety: 1 = Preview only, 0 = Execute
AS
BEGIN
    SET NOCOUNT ON;
    
    DECLARE @CutoffDate DATE = DATEADD(YEAR, -@YearsToKeep, GETDATE());
    DECLARE @RowsToArchive INT;
    
    PRINT '========================================';
    PRINT 'Production Orders Archiving Process';
    PRINT '========================================';
    PRINT 'Cutoff Date: ' + CAST(@CutoffDate AS VARCHAR(20));
    PRINT 'Mode: ' + CASE WHEN @DryRun = 1 THEN 'DRY RUN (Preview)' ELSE 'LIVE (Execute)' END;
    PRINT '========================================';
    
    BEGIN TRANSACTION
    
    BEGIN TRY
        -- Count orders to archive
        SELECT @RowsToArchive = COUNT(*)
        FROM dbo.CtiZlecenieNag WITH (NOLOCK)
        WHERE CZN_DataRealizacji < @CutoffDate;
        
        PRINT 'Orders to archive: ' + CAST(@RowsToArchive AS VARCHAR(10));
        
        IF @RowsToArchive = 0
        BEGIN
            PRINT '‚úÖ No orders to archive';
            ROLLBACK;
            RETURN;
        END
        
        -- Dry run: Show preview
        IF @DryRun = 1
        BEGIN
            PRINT 'üìä PREVIEW - Orders that would be archived:';
            SELECT TOP 100
                CZN_ID,
                CZN_TwrId,
                CZN_DataRealizacji,
                DATEDIFF(DAY, CZN_DataRealizacji, GETDATE()) as DaysOld
            FROM dbo.CtiZlecenieNag WITH (NOLOCK)
            WHERE CZN_DataRealizacji < @CutoffDate
            ORDER BY CZN_DataRealizacji ASC;
            
            ROLLBACK;
            RETURN;
        END
        
        -- Live execution
        -- Step 1: Archive order elements
        INSERT INTO dbo.CtiZlecenieElem_Archive
        SELECT e.*, GETDATE() as ArchiveDate
        FROM dbo.CtiZlecenieElem e
        JOIN dbo.CtiZlecenieNag n ON e.CZE_CZNId = n.CZN_ID
        WHERE n.CZN_DataRealizacji < @CutoffDate;
        
        DECLARE @ElementsArchived INT = @@ROWCOUNT;
        PRINT '‚úÖ Archived ' + CAST(@ElementsArchived AS VARCHAR(10)) + ' order elements';
        
        -- Step 2: Archive order headers
        INSERT INTO dbo.CtiZlecenieNag_Archive
        SELECT *, GETDATE() as ArchiveDate
        FROM dbo.CtiZlecenieNag
        WHERE CZN_DataRealizacji < @CutoffDate;
        
        PRINT '‚úÖ Archived ' + CAST(@@ROWCOUNT AS VARCHAR(10)) + ' order headers';
        
        -- Step 3: Delete from production tables (in correct order to respect FK constraints)
        DELETE e
        FROM dbo.CtiZlecenieElem e
        JOIN dbo.CtiZlecenieNag n ON e.CZE_CZNId = n.CZN_ID
        WHERE n.CZN_DataRealizacji < @CutoffDate;
        
        PRINT '‚úÖ Deleted ' + CAST(@@ROWCOUNT AS VARCHAR(10)) + ' elements from production table';
        
        DELETE FROM dbo.CtiZlecenieNag
        WHERE CZN_DataRealizacji < @CutoffDate;
        
        PRINT '‚úÖ Deleted ' + CAST(@@ROWCOUNT AS VARCHAR(10)) + ' headers from production table';
        
        -- Rebuild indexes for performance
        PRINT 'üîß Rebuilding indexes...';
        ALTER INDEX ALL ON dbo.CtiZlecenieElem REBUILD;
        ALTER INDEX ALL ON dbo.CtiZlecenieNag REBUILD;
        PRINT '‚úÖ Indexes rebuilt';
        
        COMMIT TRANSACTION;
        PRINT '‚úÖ ARCHIVING COMPLETED SUCCESSFULLY';
        
    END TRY
    BEGIN CATCH
        ROLLBACK TRANSACTION;
        
        DECLARE @ErrorMessage NVARCHAR(4000) = ERROR_MESSAGE();
        DECLARE @ErrorSeverity INT = ERROR_SEVERITY();
        
        PRINT '‚ùå ERROR: ' + @ErrorMessage;
        RAISERROR(@ErrorMessage, @ErrorSeverity, 1);
    END CATCH
END
GO

-- Step 3: Test in DRY RUN mode
EXEC dbo.usp_ArchiveOldProductionOrders @YearsToKeep = 3, @DryRun = 1;

-- Step 4: Execute (after DBA approval)
-- EXEC dbo.usp_ArchiveOldProductionOrders @YearsToKeep = 3, @DryRun = 0;
```

**SQL Server Agent Job** (schedule quarterly execution):

```sql
-- Create SQL Agent Job (wykonaƒá w SSMS)
USE msdb;
GO

EXEC sp_add_job
    @job_name = 'CTI_Archive_Old_Production_Orders',
    @enabled = 1,
    @description = 'Archives production orders older than 3 years (quarterly)';

EXEC sp_add_jobstep
    @job_name = 'CTI_Archive_Old_Production_Orders',
    @step_name = 'Archive Orders',
    @subsystem = 'TSQL',
    @database_name = 'COMARCH_DB',  -- Replace with actual DB name
    @command = 'EXEC dbo.usp_ArchiveOldProductionOrders @YearsToKeep = 3, @DryRun = 0',
    @on_success_action = 1;  -- Quit with success

-- Schedule: Quarterly on 1st day of Jan/Apr/Jul/Oct at 2 AM
EXEC sp_add_schedule
    @schedule_name = 'Quarterly_Maintenance',
    @freq_type = 16,  -- Monthly
    @freq_interval = 1,  -- Day 1 of month
    @freq_subday_type = 1,
    @active_start_time = 020000;  -- 02:00:00 AM

EXEC sp_attach_schedule
    @job_name = 'CTI_Archive_Old_Production_Orders',
    @schedule_name = 'Quarterly_Maintenance';

-- Add job to local server
EXEC sp_add_jobserver
    @job_name = 'CTI_Archive_Old_Production_Orders',
    @server_name = N'(local)';
GO
```

#### KPI Sukcesu
- **Redukcja rozmiaru bazy**: -30% po pierwszej archiwizacji (dane >3 lata)
- **Poprawa wydajno≈õci**: +20% szybsze zapytania (mniejsze tabele)
- **Compliance**: 100% zgodno≈õƒá z politykƒÖ retencji danych

---

### A.5 Integracja z Systemem Zam√≥wie≈Ñ (Purchase Order Automation)

**Priorytet**: üü† NISKI (Long-term)  
**Wysi≈Çek**: Wysoki (40-80h dev + integracje)  
**Wp≈Çyw Biznesowy**: Pe≈Çna automatyzacja procesu zakupowego, redukcja pracy manualnej

#### Problem
Obecnie proces zakupowy jest rƒôczny:
1. U≈ºytkownik widzi alert o niskim stanie
2. Manualnie tworzy zam√≥wienie w Comarch Optima (modu≈Ç Handel)
3. Brak automatycznego workflow

**<DO_POTWIERDZENIA_W_DOKUMENTACJI_OPTIMA>**  
Verify if Comarch Optima API supports programmatic creation of purchase orders (CDN.TraNag, CDN.TraElem tables). Check SDK documentation for "CDN API" or "Comarch OPT!MA SDK".
**</DO_POTWIERDZENIA_W_DOKUMENTACJI_OPTIMA>**

#### RozwiƒÖzanie (Koncepcyjne)

**Architecture Overview**:
```
AI Supply Assistant (Python)
    ‚Üì (generates purchase recommendation)
Approval Workflow (Streamlit UI)
    ‚Üì (user confirms)
Comarch Optima API / SQL Insert
    ‚Üì (creates draft PO)
Comarch Optima (Handel module)
    ‚Üí User finalizes and sends to supplier
```

**Python Integration Module** (szkic koncepcyjny):

```python
"""
Purchase Order Integration Module
Integrates with Comarch Optima's Handel module to create draft purchase orders.

‚ö†Ô∏è  CRITICAL: This is a CONCEPTUAL implementation. 
Actual implementation requires:
1. Comarch Optima API access (SDK license may be required)
2. Understanding of CDN.TraNag/CDN.TraElem schema
3. Testing in development environment
4. User acceptance testing
"""

from dataclasses import dataclass
from typing import List
import logging

logger = logging.getLogger('PurchaseOrderIntegration')

@dataclass
class PurchaseOrderLine:
    product_id: int
    product_code: str
    product_name: str
    quantity: float
    unit: str
    estimated_price: float  # From historical data or master catalog

@dataclass
class PurchaseOrder:
    supplier_id: int  # <DO_POTWIERDZENIA_W_DOKUMENTACJI_OPTIMA>: CDN.Kontrahenci.Knt_KntId
    order_date: str
    expected_delivery_date: str
    lines: List[PurchaseOrderLine]
    notes: str

class ComarchOptimaIntegration:
    """
    Integration layer for Comarch Optima ERP.
    
    ‚ö†Ô∏è  SECURITY CRITICAL:
    - Use READ COMMITTED isolation level for writes
    - Always wrap in BEGIN TRAN ... COMMIT/ROLLBACK
    - Validate all data before insertion
    """
    
    def __init__(self, db_connector):
        self.db = db_connector
    
    def create_draft_purchase_order(self, po: PurchaseOrder) -> int:
        """
        Creates a draft purchase order in Comarch Optima.
        
        Returns:
            Purchase Order ID (TraNag ID)
            
        Raises:
            Exception if creation fails
        """
        try:
            # ‚ö†Ô∏è  CONCEPTUAL IMPLEMENTATION - REQUIRES VALIDATION
            # Actual schema may differ - consult Comarch documentation
            
            query_header = """
            BEGIN TRAN
            
            -- Insert purchase order header (CDN.TraNag)
            INSERT INTO CDN.TraNag (
                TrN_GIDTyp,        -- Document type (PO = ?)
                TrN_GIDNumer,      -- Document number (auto-increment)
                TrN_KntId,         -- Supplier ID
                TrN_Data,          -- Order date
                TrN_DataWys,       -- Expected delivery
                TrN_Uwagi          -- Notes
            )
            VALUES (
                :doc_type,         -- <DO_POTWIERDZENIA>: Find correct GIDTyp for PO
                (SELECT ISNULL(MAX(TrN_GIDNumer), 0) + 1 FROM CDN.TraNag WHERE TrN_GIDTyp = :doc_type),
                :supplier_id,
                :order_date,
                :delivery_date,
                :notes
            );
            
            SELECT SCOPE_IDENTITY() as NewOrderId;
            
            -- ROLLBACK for safety - DBA must review
            ROLLBACK;
            """
            
            # Execute header insertion
            # result = self.db.execute_query(query_header, params={...})
            
            # Insert order lines (CDN.TraElem)
            # ...
            
            logger.info(f"Draft PO created (CONCEPTUAL): {po}")
            
            # Return draft PO ID
            return -1  # Placeholder
            
        except Exception as e:
            logger.error(f"Failed to create draft PO: {e}")
            raise
    
    def get_supplier_for_product(self, product_id: int) -> int:
        """
        Determines preferred supplier for a product.
        
        <DO_POTWIERDZENIA_W_DOKUMENTACJI_OPTIMA>
        Check if Comarch stores supplier-product mapping in:
        - CDN.TwrDostawcy (Product Suppliers table)
        - CDN.CenyProdDet (Supplier price lists)
        </DO_POTWIERDZENIA_W_DOKUMENTACJI_OPTIMA>
        """
        query = """
        SELECT TOP 1
            td.TwD_KntId as SupplierId,
            k.Knt_Kod as SupplierCode,
            k.Knt_Nazwa as SupplierName
        FROM CDN.TwrDostawcy td WITH (NOLOCK)
        JOIN CDN.Kontrahenci k WITH (NOLOCK) ON td.TwD_KntId = k.Knt_KntId
        WHERE td.TwD_TwrId = :product_id
        ORDER BY td.TwD_Domyslny DESC;  -- Prefer default supplier
        """
        
        # Execute query
        # ...
        
        return -1  # Placeholder
```

**UI Workflow** (Streamlit):
```python
# In dashboard view, after displaying alerts

if st.button("üõí Generuj Projekt Zam√≥wienia"):
    selected_alerts = st.multiselect("Wybierz produkty do zam√≥wienia:", alerts)
    
    if selected_alerts:
        # Create draft PO
        po_lines = [
            PurchaseOrderLine(
                product_id=alert.product_id,
                product_code=alert.product_code,
                product_name=alert.product_name,
                quantity=alert.recommended_order_qty,
                unit='kg',  # From product master
                estimated_price=0.0  # Lookup from price catalog
            )
            for alert in selected_alerts
        ]
        
        # Show preview
        st.write("PodglƒÖd zam√≥wienia:")
        st.table(pd.DataFrame([vars(line) for line in po_lines]))
        
        if st.button("‚úÖ Potwierd≈∫ i utw√≥rz projekt w Optima"):
            # Call integration
            # integration = ComarchOptimaIntegration(db)
            # po_id = integration.create_draft_purchase_order(...)
            
            st.success("‚úÖ Projekt zam√≥wienia utworzony! (ID: XXXX)")
            st.info("‚ÑπÔ∏è  Dokument dostƒôpny w Comarch Optima ‚Üí Handel ‚Üí Zam√≥wienia")
```

#### Alternatywne RozwiƒÖzanie (Low-code)
Je≈õli API Comarch nie jest dostƒôpne:
1. Export listy zam√≥wie≈Ñ do Excel (template zgodny z Comarch import)
2. U≈ºytkownik importuje do Optima przez GUI (Handel ‚Üí Import)

#### KPI Sukcesu
- **Czas procesu zakupowego**: -70% (z 30 min do 10 min)
- **B≈Çƒôdy w zam√≥wieniach**: -90% (automatyczna walidacja)
- **Zadowolenie u≈ºytkownik√≥w**: +60%

---

## üé® Kategoria B: Usprawnienia Ergonomiczne (UX)

### B.1 ‚≠ê Unified Dashboard - PrzeglƒÖd "Single Pane of Glass"

**Priorytet**: üî¥ WYSOKI (Quick Win)  
**Wysi≈Çek**: Niski (8-12h dev)  
**Wp≈Çyw Biznesowy**: Poprawa UX, redukcja czasu szukania informacji

#### Problem
Obecnie u≈ºytkownik musi prze≈ÇƒÖczaƒá siƒô miƒôdzy 3 trybami (Analiza/Predykcja/AI) aby uzyskaƒá pe≈Çny obraz. Brak centralnego dashboard'u z najwa≈ºniejszymi informacjami.

#### RozwiƒÖzanie
Ju≈º opisane w sekcji A.2 - nowy widok Dashboard z kartami KPI, alertami i mini-wykresami.

### B.2-B.5 Pozosta≈Çe Usprawnienia UX
- **B.2**: Zaawansowane filtrowanie i wyszukiwanie produkt√≥w
- **B.3**: Historia operacji u≈ºytkownika (audit trail)
- **B.4**: Responsywny layout (wsparcie mobile)
- **B.5**: Dark mode support

---

## üíº Kategoria C: Usprawnienia Biznesowe

### C.1-C.5 Kluczowe Usprawnienia Biznesowe
- **C.1**: Optymalizacja connection pool SQL (wydajno≈õƒá)
- **C.2**: Cache warming strategy (szybszy startup)
- **C.3**: Raporty compliance (RODO, GxP)
- **C.4**: Integracja z Power BI
- **C.5**: Automatyczne raportowanie do zarzƒÖdu

---

## üìÖ Harmonogram Implementacji

### Q1 2025 - Quick Wins (3 miesiƒÖce)
1. Implementacja indeks√≥w SQL (A.1)
2. Unified Dashboard (B.1)
3. Export do Excel (A.3)
4. Stock Alerting (A.2)
5. Connection Pool Optimization (C.1)

**Wysi≈Çek**: ~48h dev + DBA = 1.2 FTE

### Q2-Q4 2025 - Mid/Long-term
- Data Archiving (A.4)
- Power BI Integration (C.4)
- Purchase Order Automation (A.5)
- RODO Compliance (C.3)

---

## üìà Metryki Sukcesu (KPI)

### Technical KPIs
- Czas ≈Çadowania danych: 2.5s ‚Üí <1.0s (60% redukcja)
- Cache hit rate: 30% ‚Üí >70%
- Slow queries: 15/day ‚Üí <3/day

### Business KPIs
- Czas procesu zakupowego: 30 min ‚Üí <10 min (67% redukcja)
- Przestoje produkcji: 2/miesiƒÖc ‚Üí <0.5/miesiƒÖc (75% redukcja)
- ROI: Pozytywny w <2 miesiƒÖce

---

## üéØ Podsumowanie i Rekomendacje

### Top 5 Priorytet√≥w
1. üî¥ **A.1 Indeksy SQL** - Najwiƒôkszy wp≈Çyw na wydajno≈õƒá
2. üî¥ **B.1 Unified Dashboard** - Poprawa UX
3. üî¥ **A.3 Export do Excel** - Integracja BI
4. üü° **A.2 Stock Alerting** - Kluczowa funkcja biznesowa
5. üî¥ **C.1 Connection Pool** - Skalowno≈õƒá

### Szacunkowy TCO
- **Implementacja Q1-Q4 2025**: ~53,350 PLN
- **ROI**: 176,000 PLN/rok (oszczƒôdno≈õci czasowe) + 600,000 PLN/rok (unikniƒôte przestoje)
- **Payback Period**: <2 miesiƒÖce ‚úÖ

### Nastƒôpne Kroki
1. Tydzie≈Ñ 1: Prezentacja dla IT Manager + Product Owner
2. Tydzie≈Ñ 2: Priorytetyzacja przez steering committee
3. Tydzie≈Ñ 3-4: Szczeg√≥≈Çowe planowanie sprint√≥w
4. Tydzie≈Ñ 5+: Start implementacji (A.1 jako pilot)

---

**KONIEC DOKUMENTU**

> **Status**: ‚úÖ Kompletny - 25 propozycji optymalizacji  
> **Data**: 2024-12-29  
> **Audytor**: Senior ERP Systems Architect & Business Analyst  
> **Wersja**: 1.0 (Final)

---

**Zatwierdzenie:**
- ‚òê Product Owner: ________________________ Data: __________
- ‚òê IT Manager: __________________________ Data: __________
- ‚òê DBA: _________________________________ Data: __________
