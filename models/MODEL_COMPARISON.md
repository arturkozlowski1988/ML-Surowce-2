# ğŸ¤– PorÃ³wnanie Modeli AI - DeepSeek-R1 vs Mistral-Small vs Qwen2.5

**Data:** 28 grudnia 2024  
**Projekt:** AI Supply Assistant  
**Status:** â³ Pobieranie modeli w toku

---

## ğŸ“Š Specyfikacja Modeli

| Model | Rozmiar | Parametry | Kontekst | RAM (est.) | Opis |
|-------|---------|-----------|----------|------------|------|
| **Qwen2.5-3B** | 1.96 GB | 3B | 32k | ~4 GB | Szybki, wydajny, idealny na CPU |
| **DeepSeek-R1-14B** | ~8 GB | 14B | 32k | ~12 GB | Zaawansowane rozumowanie (R1 distilled) |
| **Mistral-Small-24B** | ~14 GB | 24B | 32k | ~18 GB | NajwyÅ¼sza jakoÅ›Ä‡, najbardziej zaawansowany |

---

## ğŸ¯ Przewidywane Zalety i Wady

### Qwen2.5-3B âœ… (Obecny)
**Zalety:**
- âœ… Bardzo szybki (najszybszy z trzech)
- âœ… Niskie wymagania RAM (~4GB)
- âœ… 32k kontekst
- âœ… Najnowszy (grudzieÅ„ 2024)
- âœ… Dobry w jÄ™zyku polskim

**Wady:**
- âš ï¸ Najmniejszy model - moÅ¼e byÄ‡ mniej precyzyjny w zÅ‚oÅ¼onych analizach
- âš ï¸ Ograniczone rozumowanie dla bardzo skomplikowanych scenariuszy

**Najlepszy dla:** Szybkie analizy, Å›rodowiska z ograniczonymi zasobami

---

### DeepSeek-R1-14B ğŸ§  (Nowy)
**Zalety:**
- âœ… **Specjalizacja w rozumowaniu (Reasoning)** - model R1
- âœ… Åšrednia wielkoÅ›Ä‡ (4x wiÄ™cej parametrÃ³w niÅ¼ Qwen)
- âœ… Dobra rÃ³wnowaga prÄ™dkoÅ›Ä‡/jakoÅ›Ä‡
- âœ… 32k kontekst
- âœ… Zaawansowana logika biznesowa

**Wady:**
- âš ï¸ Wolniejszy niÅ¼ Qwen (~3x)
- âš ï¸ Wymaga wiÄ™cej RAM (~12GB)
- âš ï¸ Åšrednia jakoÅ›Ä‡ jÄ™zyka polskiego (lepszy w EN)

**Najlepszy dla:** ZÅ‚oÅ¼one analizy logiczne, wykrywanie anomalii, rozumowanie przyczynowo-skutkowe

---

### Mistral-Small-24B ğŸš€ (Nowy)
**Zalety:**
- âœ… **NajwyÅ¼sza jakoÅ›Ä‡ odpowiedzi**
- âœ… Najlepsze rozumienie kontekstu biznesowego
- âœ… DoskonaÅ‚y w wielojÄ™zycznoÅ›ci (+ polski)
- âœ… 32k kontekst
- âœ… Najprecyzyjniejsze rekomendacje

**Wady:**
- âš ï¸ Najwolniejszy (~5-7x wolniej niÅ¼ Qwen)
- âš ï¸ Wymaga duÅ¼o RAM (~18GB)
- âš ï¸ NajwiÄ™kszy rozmiar pliku

**Najlepszy dla:** Krytyczne decyzje biznesowe, najwyÅ¼sza jakoÅ›Ä‡ analiz

---

## ğŸ” Przypadki UÅ¼ycia

### Scenariusz 1: Codzienna Analiza TrendÃ³w
**Potrzeba:** Szybkie sprawdzenie trendÃ³w zuÅ¼ycia surowcÃ³w  
**Rekomendacja:** **Qwen2.5-3B** â­â­â­â­â­
- WystarczajÄ…ca jakoÅ›Ä‡
- Natychmiastowe odpowiedzi
- Niskie zuÅ¼ycie zasobÃ³w

### Scenariusz 2: Wykrywanie Anomalii
**Potrzeba:** Identyfikacja nietypowych wzorcÃ³w i przyczyn  
**Rekomendacja:** **DeepSeek-R1-14B** â­â­â­â­â­
- Specjalizacja w rozumowaniu logicznym
- Chain-of-thought reasoning
- Lepsze wyjaÅ›nianie przyczyn

### Scenariusz 3: Strategiczne Decyzje Zakupowe
**Potrzeba:** Optymalizacja dÅ‚ugoterminowej strategii zakupÃ³w  
**Rekomendacja:** **Mistral-Small-24B** â­â­â­â­â­
- NajwyÅ¼sza jakoÅ›Ä‡ analiz
- Najbardziej przemyÅ›lane rekomendacje
- Warto poczekaÄ‡ na odpowiedÅº

### Scenariusz 4: Batch Processing (Nocna Analiza)
**Potrzeba:** Analiza 100+ produktÃ³w podczas nocy  
**Rekomendacja:** **Qwen2.5-3B** lub **DeepSeek-R1-14B**
- Qwen: JeÅ›li czas jest krytyczny
- DeepSeek: JeÅ›li jakoÅ›Ä‡ > prÄ™dkoÅ›Ä‡

---

## ğŸ’¡ Strategia Wyboru Modelu

### PodejÅ›cie 1: Single Model (Prosty)
Wybierz JEDEN model do wszystkich zadaÅ„:
- **Budget Setup:** Qwen2.5-3B
- **Balanced Setup:** DeepSeek-R1-14B âœ… **RECOMMENDED**
- **Premium Setup:** Mistral-Small-24B

### PodejÅ›cie 2: Hybrid Model (Zaawansowany)
UÅ¼ywaj rÃ³Å¼nych modeli do rÃ³Å¼nych zadaÅ„:

```python
# PrzykÅ‚ad w kodzie
if task_type == "quick_overview":
    model = "qwen2.5-3b"
elif task_type == "anomaly_detection":
    model = "deepseek-r1-14b"
elif task_type == "strategic_planning":
    model = "mistral-small-24b"
```

---

## ğŸ§ª Plan Testowania

### Testy WydajnoÅ›ciowe
1. **PrÄ™dkoÅ›Ä‡ Å‚adowania** - Czas inicjalizacji modelu
2. **Tokens/sekunda** - SzybkoÅ›Ä‡ generowania
3. **Wykorzystanie RAM** - ZuÅ¼ycie pamiÄ™ci

### Testy JakoÅ›ciowe
1. **Analiza trendu** - Czy poprawnie identyfikuje wzrosty/spadki?
2. **Wykrywanie anomalii** - Czy rozpoznaje nietypowe sytuacje?
3. **Rekomendacje** - Czy sugestie sÄ… praktyczne i uÅ¼yteczne?
4. **JÄ™zyk polski** - JakoÅ›Ä‡ gramatyki i stylu
5. **Kontekst biznesowy** - Czy rozumie specyfikÄ™ supply chain?

---

## ğŸ“ Jak UruchomiÄ‡ Testy

### Automatyczny Test PorÃ³wnawczy
```bash
# Uruchom skrypt porÃ³wnawczy (gdy wszystkie modele bÄ™dÄ… pobrane)
python scripts/compare_models.py
```

To uruchomi wszystkie 3 modele z tymi samymi promptami i wygeneruje raport.

### RÄ™czny Test w Aplikacji
```bash
# Uruchom aplikacjÄ™
streamlit run main.py

# PrzejdÅº do sekcji AI Assistant
# Wybierz "Local LLM (Embedded)"
# Edytuj .env aby zmieniÄ‡ LOCAL_LLM_PATH na:
#   - models/qwen2.5-3b-instruct-q4_k_m.gguf
#   - models/deepseek-r1-14b-q4_k_m.gguf  
#   - models/mistral-small-24b-q4_k_m.gguf
```

---

## ğŸ“ Kryteria Wyboru - Decision Matrix

| Kryterium | Waga | Qwen2.5 | DeepSeek-R1 | Mistral-Small |
|-----------|------|---------|-------------|---------------|
| PrÄ™dkoÅ›Ä‡ | 25% | â­â­â­â­â­ | â­â­â­ | â­â­ |
| JakoÅ›Ä‡ odpowiedzi | 35% | â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| Wymagania RAM | 15% | â­â­â­â­â­ | â­â­â­ | â­â­ |
| JÄ™zyk polski | 15% | â­â­â­â­ | â­â­â­ | â­â­â­â­â­ |
| Rozumowanie | 10% | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ |

**Weighted Score:**
- **Qwen2.5-3B:** 3.65/5 - Najszybszy i wydajny
- **DeepSeek-R1-14B:** 3.80/5 - âœ… **Najlepszy balans**
- **Mistral-Small-24B:** 4.10/5 - NajwyÅ¼sza jakoÅ›Ä‡ (jeÅ›li masz RAM)

---

## ğŸš€ Rekomendacje

### Dla Twojego Projektu (AI Supply Assistant)

1. **Testuj wszystkie 3** - Pobierz, uruchom compare_models.py
2. **UÅ¼yj DeepSeek-R1 jako gÅ‚Ã³wnego** - Najlepszy balans dla supply chain
3. **Zachowaj Qwen2.5 jako backup** - Na wypadek brakÃ³w zasobÃ³w
4. **Mistral-Small na produkcjÄ™** - JeÅ›li klient ma mocny sprzÄ™t

### Implementacja w Kodzie

MoÅ¼esz dodaÄ‡ selektor modelu w aplikacji:
```python
model_choice = st.selectbox(
    "Wybierz model AI:",
    ["Qwen2.5-3B (Szybki)", "DeepSeek-R1-14B (Balanced)", "Mistral-Small-24B (Premium)"]
)
```

---

## ğŸ“š Dodatkowe Informacje

### DeepSeek-R1
- Å¹rÃ³dÅ‚o: https://huggingface.co/deepseek-ai/DeepSeek-R1
- SpecjalnoÅ›Ä‡: Chain-of-Thought Reasoning
- Technologia: Distilled from DeepSeek-R1-671B

### Mistral-Small
- Å¹rÃ³dÅ‚o: https://mistral.ai/news/mistral-small/
- SpecjalnoÅ›Ä‡: Enterprise-grade LLM
- Technologia: Mistral architecture (Sep 2024)

### Qwen2.5
- Å¹rÃ³dÅ‚o: https://github.com/QwenLM/Qwen2.5
- SpecjalnoÅ›Ä‡: Fast inference, multilingual
- Technologia: Latest Qwen series (Dec 2024)

---

**Status pobierania:**
- âœ… Qwen2.5-3B - Gotowy
- â³ DeepSeek-R1-14B - Pobieranie...
- â³ Mistral-Small-24B - Pobieranie...

**NastÄ™pny krok:** Po zakoÅ„czeniu pobierania uruchom `python scripts/compare_models.py`
