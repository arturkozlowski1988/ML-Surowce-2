"""
Quick test for DeepSeek-R1 14B model.
Tests basic functionality before full comparison.
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.ai_engine.local_llm import LocalLLMEngine

def test_deepseek():
    """Quick test of DeepSeek-R1 model."""
    
    model_path = "models/deepseek-r1-14b-q4_k_m.gguf"
    
    print("="*80)
    print("DeepSeek-R1 14B - Quick Test")
    print("="*80)
    
    if not Path(model_path).exists():
        print(f"âŒ Model not found: {model_path}")
        return
    
    print(f"\nâœ… Model file found: {model_path}")
    print(f"Size: {Path(model_path).stat().st_size / (1024**3):.2f} GB")
    
    print("\nâ³ Loading model (this may take 30-60 seconds)...")
    
    engine = LocalLLMEngine(
        model_path=model_path,
        n_ctx=4096,
        verbose=False
    )
    
    # Test prompt
    test_prompt = """Przeanalizuj nastÄ™pujÄ…cy trend zuÅ¼ycia surowca:

Surowiec: STAL 316L
Trend: Wzrost o 35% w ostatnich 3 miesiÄ…cach
Åšrednie zuÅ¼ycie: 2500 kg/miesiÄ…c
Obecne zuÅ¼ycie: 3375 kg/miesiÄ…c
Dni do wyczerpania zapasu: 12 dni

Podaj krÃ³tkÄ… analizÄ™ i rekomendacjÄ™ dla dziaÅ‚u zakupÃ³w."""
    
    print("\nğŸ“ Test prompt:")
    print("-" * 80)
    print(test_prompt)
    print("-" * 80)
    
    print("\nğŸ¤– Generating response...")
    response = engine.generate_explanation(test_prompt)
    
    print("\nğŸ’¡ Response:")
    print("="*80)
    print(response)
    print("="*80)
    
    # Stats
    words = len(response.split())
    print(f"\nğŸ“Š Response stats:")
    print(f"   Words: {words}")
    print(f"   Characters: {len(response)}")
    
    print("\nâœ… DeepSeek-R1 test completed successfully!")
    print("\nğŸ’¡ Next step: Run full comparison with:")
    print("   python scripts/compare_models.py")

if __name__ == "__main__":
    test_deepseek()
